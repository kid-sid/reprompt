# ğŸ¤– Reprompt - AI Prompt Optimizer

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.100+-green.svg)](https://fastapi.tiangolo.com)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-orange.svg)](https://openai.com)
[![Supabase](https://img.shields.io/badge/Supabase-Auth-purple.svg)](https://supabase.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A production-ready FastAPI application that optimizes user prompts using AI to make them more efficient and effective. Features dual inference modes (Lazy/Pro), user authentication, Redis caching, prompt history, feedback system, and a modern web interface.

## âœ¨ Features

### ğŸ” **Authentication System**
- **User Registration & Login** with email/password
- **JWT Token Management** with access and refresh tokens
- **Protected Routes** with authentication middleware
- **User Profile Management** with Supabase integration
- **Secure Session Handling** with automatic token refresh
- **Rate Limiting** (5 requests/minute) for auth operations
- **Security Features** including failed login tracking and account lockout

### ğŸ¤– **AI Inference Engine**
- **Dual Mode Operation**:
  - **Lazy Mode**: Fast, cost-effective optimization (gpt-4o-mini, 250 tokens)
  - **Pro Mode**: Advanced, detailed optimization (gpt-4o, 2500 tokens)
- **Smart Parameter Configuration** based on mode selection
- **Input Validation & Sanitization** for security
- **Comprehensive Error Handling** with detailed logging
- **OpenAI API Rate Limiting** (60 requests/minute) for external API protection
- âš ï¸ **Note**: Inference endpoints need rate limiting implementation

### ğŸ“ **Prompt History & Feedback**
- **Complete Prompt History** with CRUD operations
- **User-specific History** with pagination and search
- **Like/Dislike Feedback** system with analytics
- **Feedback Statistics** and user summaries
- **Database Integration** with proper relationships and RLS

### ğŸš€ **Performance & Infrastructure**
- **Redis Caching** for optimized response times
- **Rate Limiting** for authentication and OpenAI API calls
- **CORS Configuration** for cross-origin requests
- **Health Check Endpoints** for monitoring
- **Structured Logging** with Loguru
- **Environment-based Configuration** for different deployments

### ğŸŒ **Modern Web Interface**
- **Responsive Design** with dark/light theme toggle
- **Real-time Chat Interface** with message history
- **Mode Selection** (Lazy/Pro) with visual indicators
- **Authentication UI** with login/register forms
- **Loading States & Error Handling** for better UX

### ğŸ›¡ï¸ **Security & Guardrails**
- **Comprehensive Security Documentation** with guardrails prompts
- **Input Validation** and sanitization
- **Error Handling** without information leakage
- **JWT Authentication** with secure token management
- **Content Filtering Guidelines** (documentation ready)
- **Quality Control Standards** (documentation ready)

## ğŸ—ï¸ Architecture

```
reprompt/
â”œâ”€â”€ ğŸ“ routes/              # API route handlers
â”‚   â”œâ”€â”€ auth_router.py      # Authentication endpoints
â”‚   â”œâ”€â”€ inference_router.py # AI inference endpoints
â”‚   â”œâ”€â”€ prompt_history_router.py # Prompt history management
â”‚   â””â”€â”€ feedback_router.py  # Feedback system endpoints
â”œâ”€â”€ ğŸ“ services/            # Business logic services
â”‚   â”œâ”€â”€ auth_service.py     # Authentication service with rate limiting
â”‚   â”œâ”€â”€ openai_service.py   # OpenAI API integration with rate limiting
â”‚   â”œâ”€â”€ redis.py           # Redis caching service
â”‚   â”œâ”€â”€ prompt_history_service.py # Prompt history management
â”‚   â””â”€â”€ feedback_service.py # Feedback system service
â”œâ”€â”€ ğŸ“ models/              # AI model implementations
â”‚   â”œâ”€â”€ lazy_inference.py  # Fast optimization model
â”‚   â””â”€â”€ pro_inference.py   # Advanced optimization model
â”œâ”€â”€ ğŸ“ schemas/             # Pydantic data models
â”‚   â”œâ”€â”€ auth_schema.py     # Authentication schemas
â”‚   â”œâ”€â”€ inference_schema.py # Inference schemas
â”‚   â”œâ”€â”€ prompt_history_schema.py # Prompt history schemas
â”‚   â””â”€â”€ feedback_schema.py # Feedback schemas
â”œâ”€â”€ ğŸ“ static/              # Frontend assets
â”‚   â”œâ”€â”€ chatbot.html       # Main chat interface
â”‚   â”œâ”€â”€ auth.html          # Authentication page
â”‚   â”œâ”€â”€ chatbot.js         # Frontend JavaScript
â”‚   â””â”€â”€ auth.js            # Auth JavaScript
â”œâ”€â”€ ğŸ“ prompts/             # AI context and guardrails
â”‚   â”œâ”€â”€ guardrails/        # Security and quality control prompts
â”‚   â”‚   â”œâ”€â”€ security.md    # Security guidelines and prompts
â”‚   â”‚   â”œâ”€â”€ content_filter.md # Content filtering rules
â”‚   â”‚   â”œâ”€â”€ quality_control.md # Quality control standards
â”‚   â”‚   â”œâ”€â”€ rate_limiting.md # Rate limiting guidelines
â”‚   â”‚   â””â”€â”€ README.md      # Guardrails overview
â”‚   â”œâ”€â”€ core/              # Core inference context
â”‚   â”‚   â”œâ”€â”€ context.md     # Core context definitions
â”‚   â”‚   â”œâ”€â”€ examples.md    # Example prompts and responses
â”‚   â”‚   â”œâ”€â”€ requirements.md # Prompt requirements
â”‚   â”‚   â””â”€â”€ tone.md        # Tone and style guidelines
â”‚   â”œâ”€â”€ enhancements/      # Prompt enhancement strategies
â”‚   â”‚   â”œâ”€â”€ audience.md    # Audience-specific adaptations
â”‚   â”‚   â”œâ”€â”€ constraints.md # Constraint handling
â”‚   â”‚   â”œâ”€â”€ objectives.md  # Objective setting
â”‚   â”‚   â””â”€â”€ terminology.md # Terminology guidelines
â”‚   â”œâ”€â”€ domain_specific/   # Domain-specific contexts
â”‚   â”‚   â”œâ”€â”€ academic.md    # Academic writing context
â”‚   â”‚   â”œâ”€â”€ business.md    # Business communication context
â”‚   â”‚   â”œâ”€â”€ marketing.md   # Marketing content context
â”‚   â”‚   â””â”€â”€ technical.md   # Technical documentation context
â”‚   â””â”€â”€ README.md          # Prompts directory overview
â”œâ”€â”€ ğŸ“ testing/             # Test suite
â”œâ”€â”€ ğŸ“ utils/               # Utility functions
â”œâ”€â”€ ğŸ“ database/            # Database schemas
â”œâ”€â”€ main.py                 # FastAPI application entry point
â”œâ”€â”€ config.py               # Configuration management
â””â”€â”€ requirements.txt        # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+**
- **OpenAI API Key**
- **Supabase Project** (for authentication)
- **Redis Server** (optional, for caching)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd reprompt
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   # Create .env file with the following variables:
   ```

5. **Set up environment variables**
   ```env
   # OpenAI Configuration
   OPENAI_API_KEY=your_openai_api_key_here
   
   # Supabase Configuration
   SUPABASE_URL=your_supabase_project_url
   SUPABASE_ANON_KEY=your_supabase_anon_key
   SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key
   
   # Redis Configuration (Optional)
   REDIS_HOST=localhost
   REDIS_PORT=6379
   REDIS_PASSWORD=your_redis_password
   
   # Server Configuration
   HOST=0.0.0.0
   PORT=8001
   LOG_LEVEL=INFO
   
   # Security Configuration
   JWT_SECRET_KEY=your_jwt_secret_key_here
   CORS_ORIGINS=["http://localhost:3000", "http://localhost:8001"]
   ```

6. **Set up database**
   ```bash
   # Run the SQL scripts in database/ folder in your Supabase project
   # - supabase.sql (main database setup)
   # - prompt_history.sql (prompt history tables)
   # - feedback.sql (feedback system tables)
   ```

7. **Run the application**
   ```bash
   python main.py
   ```

8. **Access the application**
   - **API Documentation**: http://localhost:8001/docs
   - **Web Interface**: http://localhost:8001/static/chatbot.html
   - **Authentication**: http://localhost:8001/static/auth.html

## ğŸ“– API Documentation

### Authentication Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/auth/signup` | Register a new user |
| `POST` | `/api/v1/auth/login` | Authenticate user |
| `POST` | `/api/v1/auth/logout` | Logout user |
| `POST` | `/api/v1/auth/refresh` | Refresh access token |
| `GET` | `/api/v1/auth/profile` | Get user profile |
| `GET` | `/api/v1/auth/validate` | Validate JWT token |

### Inference Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/optimize-prompt` | Optimize user prompt |
| `GET` | `/api/v1/cache/stats` | Get cache statistics |
| `DELETE` | `/api/v1/cache/clear` | Clear cache |

### Prompt History Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/prompt-history` | Get user's prompt history |
| `POST` | `/api/v1/prompt-history` | Save prompt optimization |
| `GET` | `/api/v1/prompt-history/{id}` | Get specific prompt history |
| `PUT` | `/api/v1/prompt-history/{id}` | Update prompt history |
| `DELETE` | `/api/v1/prompt-history/{id}` | Delete prompt history |

### Feedback Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v1/feedback` | Submit feedback |
| `GET` | `/api/v1/feedback/stats` | Get feedback statistics |
| `GET` | `/api/v1/feedback/user/{user_id}` | Get user feedback summary |

### Example API Usage

**Register a new user:**
```bash
curl -X POST "http://localhost:8001/api/v1/auth/signup" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "securepassword123"
  }'
```

**Login:**
```bash
curl -X POST "http://localhost:8001/api/v1/auth/login" \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "securepassword123"
  }'
```

**Optimize a prompt:**
```bash
curl -X POST "http://localhost:8001/api/v1/optimize-prompt" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -d '{
    "prompt": "Write a story about a robot",
    "inference_type": "pro",
    "max_tokens": 1000
  }'
```

**Get prompt history:**
```bash
curl -X GET "http://localhost:8001/api/v1/prompt-history" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default | Required |
|----------|-------------|---------|----------|
| `OPENAI_API_KEY` | OpenAI API key | - | âœ… |
| `SUPABASE_URL` | Supabase project URL | - | âœ… |
| `SUPABASE_ANON_KEY` | Supabase anonymous key | - | âœ… |
| `SUPABASE_SERVICE_ROLE_KEY` | Supabase service role key | - | âœ… |
| `REDIS_HOST` | Redis server host | localhost | âŒ |
| `REDIS_PORT` | Redis server port | 6379 | âŒ |
| `REDIS_PASSWORD` | Redis password | - | âŒ |
| `HOST` | Server host | 0.0.0.0 | âŒ |
| `PORT` | Server port | 8001 | âŒ |
| `JWT_SECRET_KEY` | JWT secret key | - | âœ… |
| `CORS_ORIGINS` | CORS allowed origins | ["*"] | âŒ |

### Model Configuration

| Mode | Model | Max Tokens | Temperature | Use Case |
|------|-------|------------|-------------|----------|
| **Lazy** | gpt-4o-mini | 250 | 0.3 | Quick, cost-effective optimization |
| **Pro** | gpt-4o | 2500 | 0.7 | Detailed, advanced optimization |

### Rate Limiting Configuration

| Service | Rate Limit | Window | Purpose |
|---------|------------|--------|---------|
| **Authentication** | 5 requests | 1 minute | Prevent brute force attacks |
| **OpenAI API** | 60 requests | 1 minute | Respect OpenAI limits |
| **Inference Endpoints** | âš ï¸ **NOT IMPLEMENTED** | - | **CRITICAL GAP** |

## ğŸš€ Deployment

### Production Deployment

1. **Set up production environment variables**
2. **Configure reverse proxy** (nginx/Apache)
3. **Set up SSL certificates**
4. **Configure Redis for caching**
5. **Set up monitoring and logging**
6. **âš ï¸ CRITICAL: Implement rate limiting for inference endpoints**

### Docker Deployment

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8001

CMD ["python", "main.py"]
```

### Environment-specific Configuration

- **Development**: Debug logging, CORS enabled
- **Staging**: Production-like with test data
- **Production**: Optimized performance, security hardening

## ğŸ“Š Performance Metrics

- **Response Time**: < 2s (Lazy), < 5s (Pro)
- **Rate Limit**: 60 requests/minute (OpenAI), 5 requests/minute (Auth)
- **Concurrent Users**: Limited by OpenAI rate limits
- **Cache Hit Rate**: Depends on Redis usage
- **Uptime**: 99.9% (with proper infrastructure)

## ğŸ”’ Security Features

- **JWT Authentication** with secure token management
- **Input Validation** and sanitization
- **Rate Limiting** for authentication and OpenAI API calls
- **CORS Configuration** for secure cross-origin requests
- **Environment Variable Protection** for sensitive data
- **Error Handling** without information leakage
- **Guardrails Documentation** for security, content filtering, and quality control

### ğŸš¨ Security Considerations

- **Rate Limiting Gap**: Inference endpoints need rate limiting implementation
- **Cost Protection**: Implement user-based limits to prevent expensive API abuse
- **Guardrails**: Security prompts documented but not actively enforced

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Setup

```bash
# Install development dependencies
pip install -r requirements.txt
pip install pytest black isort pylint

# Run code formatting
black .
isort .

# Run linting
pylint .

# Run tests
pytest testing/
```

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Documentation**: Check this README and inline code comments
- **Issues**: Create GitHub issues for bugs or feature requests
- **Discussions**: Use GitHub Discussions for questions and ideas

## ğŸ¯ Roadmap

### Phase 2 (Next Release) - Security Focus
- ğŸ”¥ **CRITICAL**: Implement inference endpoint rate limiting
- ğŸ”¥ **CRITICAL**: Add user-based rate limiting system
- ğŸ”¥ **CRITICAL**: Implement Redis-based distributed rate limiting
- [ ] Frontend integration for prompt history management
- [ ] Frontend integration for feedback display
- [ ] Advanced caching strategies and analytics
- [ ] User dashboard and preferences

### Phase 3 (Future)
- [ ] Custom model fine-tuning
- [ ] Multi-language support
- [ ] Advanced prompt templates
- [ ] Team collaboration features
- [ ] Enterprise features
- [ ] Active guardrails enforcement
- [ ] Monitoring using Grafana

## ğŸš¨ Important Notes

### Production Readiness
This application is **production-ready** with comprehensive features, but has **critical security gaps** that must be addressed before deployment:

1. **Rate Limiting**: Inference endpoints are completely unprotected
2. **Cost Risk**: Users can make unlimited expensive OpenAI API calls
3. **Security**: Guardrails are documented but not actively enforced

### Immediate Action Required
Before production deployment, implement:
- Rate limiting for inference endpoints
- User-based usage limits
- Active guardrails enforcement
- Cost monitoring and alerts

---

**Built with â¤ï¸ using FastAPI, OpenAI, Supabase, and Redis**